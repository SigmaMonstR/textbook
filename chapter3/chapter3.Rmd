# Chapter 3: A Light Introduction to Statistical Programming

__Main question of the chapter:__  How do I get started?

__Gist:__  Bare-bone basics: Going deeper into the basics of R. Types of data and objects. Installing packages. Importing data and directories.

## Data are everywhere—and they come in all types.

- We see data everywhere, including news reports: "The Dow Jones industrial average erased earlier losses today to end 56.97 points higher at 21,865.37..."".
  - Each piece of information corresponds to a different data type (e.g., numeric, string, factors, Boolean, dates).
  - "Dow Jones industrial average" references the name of a specific stock-market index.
  - "today" references a date (as does "earlier")
  - "56.97" and "21,865.37" are numbers (with units)
  - There are also data embedded in the phrases "erased", "earlier losses" and "higher".

## Data types

In R, you encode (often implicitly) your variables/data as having one of several types of data, e.g., `numeric`, `logical`, `character`, `factor`, or `date`.

### `numeric`

As you might guess, ‘numeric' data are numbers. The numeric type is R's catch-all for all numbers, encompassing both integer and continuous numbers.

### `logical`

If you want to test whether something is true or false, then you've found yourself in the world of logic. Because programming and data science use logical data so frequently, they get their own data type. In R, logical data are `TRUE` or `FALSE`, which you can abbreviate as `T` or `F`. As is always the case in R: the letters' cases matter (meaning you must use `TRUE` and cannot use `true`).

### `character`

You will most often encounter `character` data (also strings as _strings_) in datasets of linguistic text—e.g., court transcripts, novels, text messages, or government audit reports.

### `factor`

Factors are a bit of special data type in R, because they allow you to take one type of variable (e.g., `numeric` or `character`) and add a few more layers of information. For instance, you can add labels to your data (so that the values "Sun" and "Mon" are labeled "Sunday" and "Monday") and you also have the option to indicate that the data are order (meaning Sunday precedes Monday). You can manipulate these labels, the ordering, and a number of other factor options through the functions `factor` and `as.factor`.

### `date`

While there are many ways to think about dates—`character` data like "January" or `numeric` data like `1`—dates are so common (and so strange to work with) that they get their own type of data, namely, the `date` type.

### The `class` function.

Just looking at a dataset does not always tell you the type of data. The question of type is particularly important when you read data into R from another source—you will not always know whether R read a variable as numeric, character, factor, or perhaps factor. The `class` function helps you here.

Let's see `class` is action...

```{R, ch3 class type examples}

class(56.97)
class(57)
class(57L)

class("Dow Jones")
Sys.Date; class(Sys.Date)
Date("2015-12-31"); class(Date("2015-12-31"))
class(class)
# <Mind blows>
```

## Objects in R

Simply entering data into R's console is not going to be enough. We need a way to store the data in our computer's memory. To be able to access the data that we store, we need to give the data a name. In R parlance, we need a way to assign the values (the data) to objects stored in memory (the names).

R's assignment operator `<-` exists solely for the task of assigning a value (on the right-hand side) to the .

`object <- value` is read "object gets value."

__Examples__

- `a <- 3`
- `string_ex <- "Some funny/clever words."`
- `some_logic <- TRUE`

As you can see, you get a lot of freedom in the names that you use for the objects.
Examples of `class` with assigned objects.

## R's object classes

### `vector`

- Vectors are one of the simplest and most used classes of objects in R.
- In R, a vector is a one-dimensional ‘list' of values. The values can be logical, numeric, factor, or character, but they must all be of the same type. If they are not, R will coerce them to the most conducive type.
- The simplest way to create a vector is with the concatenate function: `c`. For instance, to create a vector out of the numbers 1, 2, and 3, we write `c(1, 2, 3)`.
- __TODO__ Coercion example...  

### `matrix`

- R's matrices are very close what your mathematics courses taught you: they are rows and columns filled with data. You can fill your R matrices with numbers, but you can also fill them with other types of data—just as you can with vectors.
- The matrix function in R takes two arguments...
- __TODO__ Example

### The `class` function again!

__TODO__

### `data frame`

__TODO__

### `list`

### More classes

R offers many other object classes. Many of the object classes are specific to an application (e.g., geographic data like rasters or shape files) or packages (e.g., when you run a regression with the function `lm`, the function produces a special `lm` object).

## Packages

### Base R and filling the need for more functions

When you boot up R, you automatically have access to a large set of functions. You can perform mathematical operations (addition `+`, division `/`), conduct statistical summaries (`mean`, `sd`), run a regression (e.g. `lm`), plot a histogram (`hist`) and even make a map (`plot`). This original set of functions that shipped with R is called *base R* -- the basic setup when you open the box. Eventually, you will find yourself in a situation in which you need to conduct more complex and specialized tasks that are not possible by any function in base R.

Some may have the adventurous itch to program specialized functions, which may sound daunting. But fear not, there is a whole universe of functions awaiting your use on the Comprehensive R Archive Network ([CRAN](https://cran.r-project.org/)) as well as on [Github](https://github.com/). Specifically, functions are available as families of functions, formally called *packages*.

For example, imagine some crazy, hypothetical world (such as the one in which we live) where someone sends you an Excel spreadsheet that you then need to load into R. Herein lies the problem: *base R does not have a function to read directly from a spreadsheet*. But, as its name implies the `readxl` package on CRAN provides exactly the functionality you need.

### Installing packages

A large community of R users and developers contribute and maintain a (vast archive of packages)[https://cran.r-project.org/web/packages/available_packages_by_name.html]. And these package span computationally intensive tasks like reading satellite imagery to more visual tasks like creating interactive maps for websites. It is easy to tap into these vast resources, and to get started with a package like `readxl`, we only need two inputs: (A) an internet connection and (B) R's `install.packages` function.

To install `readxl`, you can install the `readxl` package by executing the following line in the R console. To break it down, `install.packages` requires the name of a known package on CRAN in the form of a string value.

```{r, eval = FALSE}
  install.packages("readxl")
```

For some packages, R will also install package dependencies -- other packages on which the request package relies. This is one of the beautiful things about R: it is an extensible language that builds on existing functionality. Entire families of packages are dependent on common functions, ensuring that a common logic is employed in making the magic happen with data.

There are sources (e.g., [METACRAN](https://www.r-pkg.org/)) that allow you to search CRAN for packages, but, as with many R-related tasks, Google and asking friends and colleagues are going to be your best bets.

### Loading packages

Like installing a new air conditioning unit, the unit is only useful when it is plugged in and turned on. R packages follow the same logic. Installing a package simply means that you now have access to the package on your machine. To take advantage of the functionality,  packages need to be loaded into R environment during each session.

To load a package, you use the `library` function in combination with the package's name. Note that whereas `install.packages` expects the package name in string format, the `library` function can accommodate both strings (e.g. "readxl") or the package as a name  (e.g. readxl) as it is now an installed resource.

```{r, eval = FALSE}
  library(readxl)
```

The `library` function will only load one package at a time, meaning that every package will need to be called individually. If we needed to load two installed packages -- `readxl` and a package for text manipulation known as `tidytext` --  we would need to do the following:

```{r, eval = FALSE}
  library(readxl)
  library(tidytext)
```

For highly complex projects requiring many packages, this will be cumbersome. We will have a fix for this shortcoming later on.

When a package is loaded, it is only temporarily help in the computer's memory. Whenever R and RStudio are closed or restarted, all loaded packages are removed from memory.  The point: you will need to load the packages again, but you do not need to install them again.

### Package management and `pacman`

While installing, loading, and updating packages in R is fairly quick and easy, the `pacman` further streamlines and simplifies these process (and many related processes). What if we needed to load these three packages? The manual option requires one to embrace the tedium:

```{r, eval = FALSE}
  library(readxl)
  library(tidytext)
  library(ggplot2)
  ...
```

And the tedium does not end on your computer. When the code is shared with a collaborator, they may not have all of the packages installed, meaning the script will *crash*, requiring them to backtrack through the error log and install all of the missing packages. This scenario happens all too often, but it need not be the case.

Meet: `pacman`.

Upon installing `pacman`, the mental overhead of keeping track of all packages is quickly minimized:

```{r, eval = FALSE}
  library(pacman)
  p_load(readxl, tidytext, ggplot2)
```

Ω
The `p_load` function within the `pacman` package makes package management easy. Not only does `p_load` install requested but missing packages, it loads them. Now, including this line of code at the top of each R script only requires collaborators to have `pacman` installed and the package does all of the heavy lifting of keeping packages up-to-date and in sync. 

#### Quick Exercise {-}

There are [X] packages that greatly expand the capabilities of R. And these packages will re-appear again and again throughout this book, namely:

- *readxl*:
- *tidytext*:
- *data.table*:
- *dplyr*: 
- *ggplot2*:
- *caret*: 

Write a command to import these core R packages.


## Data I/O

When Captain Jean Luc Picard says "Make it so, Number Two", he is giving the order to execute a command that he specified prior to his statement. All the necessary information needed by the starship's crew to act is embedded in that order, ensuring that a precise output is delivered according to Picard's input. Our interaction with computers is no different. At least at present,  computer programs cannot guess what we intend to do -- although not yet. Computers are designed to interact and respond to humans given specific rules and protocols, and importing data is no different. This is the fundamental idea that underlies data *Input/Output*.

Suppose you need to analyze an Excel file of stock market data. In order to load the data, we need three pieces of information: 

```{r, echo = FALSE, message=FALSE, warning=FALSE}
p_load(DiagrammeR)
mermaid("graph LR
        A[Directory] --> B[Function]
        B --> C[File]",
        height = 200)
```

R needs to know where to look for a file (*directory*), how to load the file (*function*), and the name of file (*file*). 

#### Directories {-}

R can import any file, so as long as it is told where to look. By default, the 

  - Defining directories: Special strings
  - directory paths should have forward slashes
  - RStudio helps you complete (tab)
  - Tips: Avoid using paths with spaces -- replace spaces with underscores "_"
  - Name paths that are rememberable
For example, 
```{r, eval = FALSE}
#Acceptable Path
  main_dir <- "/Users/BlackPanther/Wakanda/NewData/"

#Will lead to error
  main_dir <- "\Users\BlackPanther\Wakanda\NewData\"

```

- Navigating directories
  - `getwd`, `setwd`, and `dir`

Best practice: Define your directories to objects at the start of your script.

```{r, eval = FALSE}
#Set directory path
  setwd(main_dir)
  
#Check path
  getwd()

#Get list of files in current directory 
  dir()
```

#### Load Functions {-}

- When you want to input data in R, you want to the right function for your data's file type. - For instance, we will use the `read_csv` function (from the `readr` package) to read .csv files, whereas we will use the `read_dta` function (from the `haven` package) to read Stata .dta files.
- Assuming you know the name of the file that you want to load, we are now set!
  - Put it all together... __TODO__
  - Example... [Question -- should the DIY be plopped in here?__TODO__


## Finding help

### Help function

Developers interested in driving adoption of their packages understand that ease of use and clear documentation win the day. Thus, each R function is equipped with documentation to illustrate its syntax and use. As a first line of support, you can access any function's help file using `?<package_name>` in the console. 

For instance, suppose you are interested in importing a spreadsheet using the `read_xlsx` from the `readxl` package, but you would like to have a better understand how to use it. Assuming that `readxl` has been loaded, simply execute the following in the console `?read_xlsx`. If the package has not already been loaded,  include the package's name, double colons (`::`), and the function's name, e.g., `?readxl::read_xlsx`. The double colon trick essentially is short hand for obtaining a specific function from a library without importing the entire library and is not restricted to looking up help files.

### Google and online communities

One of the best aspects of R is the vibrant and (generally) helpful online community. By simply searching "*R <issue goes here>*", you will likely discover that you are not the first to have faced the challenge at hand. To illustrate the point:

- *Leading zeroes* often are required to convert a number to a certain format. One of the zipcodes for Somerville, MA is `02144`, which sometimes is erroneously converted into a number `2144`. To find a solution to this formatting issue, simply search "*R leading zeroes*".
- *JSON* or JavaScript Object Notation is a data format that is increasingly used for web data. It requires a package to read and import. Search "*R import JSON*" to find a solution.

It quickly becomes apparent that [Stack Overflow](https://stackoverflow.com/) is a key resource for programming and [Cross Validated](https://stats.stackexchange.com/) for statistics and machine learning. More often than not, these online communities will have an answer and R coders hunting for an answer will copy and paste code without checking what it does. User beware, the answer might not be to your question, be the most efficient, or accurate. Nonetheless, these online resources are a great starting point.


## Best practices: Commenting your scripts

As you may have noticed, many of the code snippets in this chapter contained comments preceded by a hash (`#`).^[Also called a _pound sign_ or _number sign_ or _octothorpe_ in the olden days before Twitter.] The hash tells R to ignore whatever follows the hash _on the same line as the `#`_. Thus, the hash allows you to make notes (generally called comments) to yourself, your collaborators, or anyone else who may have to read through your code. These comments help you figure out what you (or your friend) were doing two years ago when you wrote the R script. For instance:

```{r, ch3 comment self, eval = F}
  # Make sure the packages are installed and loaded.
  p_load(readxl, dplyr)
  # Navigate to the data directory to load the data.
  setwd("/Users/Someone/OnlyData")
  # Load the xlsx file (named 'fake_data.xlsx')
  fake_df <- read_xlsx("fake_data.xlsx")
```

In the example above, each comment line briefly describes what we will do in the next line and why we want to do it. Often the _why_ is the most important part: with some experience, you will be able to figure out what each line of an R script does, but it is much more difficult to figure out _why_ the author wrote the 641 lines of code in the middle of a 1200-line R script.

Another popular use of comments in R—and in many other languages—is to flag questions, issues, or unfinished items. The idea here is to start the comment with a quick flag, for instance `# TODO`. This flag helps you find the unfinished parts of your document—or the parts that you want your collaborators to finish for you. For instance, we might start a document
```{R, ch3 flag ex, eval = F}
  # Make sure the packages are installed and loaded
  # FIXME: There are better packages for large datasets.
  p_load(readxl, dplyr)
  # Navigate to the data directory to load the data
  setwd("/Users/Someone/OnlyData")
  # Load the xlsx file (named 'fake_data.xlsx')
  fake_df <- read_xlsx("fake_data.xlsx")
  # TODO: Clean the dataset. Check out `stringr` and `data.table`
```

You can also use commenting (`#`) to tell R to ignore lines of code. This usage of the hash is called _commenting out_ your code, as it allows you to turn off a line of code, e.g.,
```{R, ch3 comment out, eval = F}
# Standard line of code
two_plus_two <- 2 + 2
# Commented out line of code
# two_times_two <- 2 * 2
```
In general, commenting lines of code out is most helpful for temporary changes and/or testing code. If you really do not need a code, just delete it.

Finally, it is worth saying that the style and amount of commenting, flagging, and commenting-out are highly subjective. If you find them burdensome, then you probably should cut back a bit or try a different strategy. That said, it's pretty rare for 0 comments to be an optimal number of comments in an R script.

## DIY

### Loading solar energy data from the web

Solar energy generation has been rapidly gaining ground. In the period between 2008 and 2017, annual net generation of solar energy produced by utility scale facilities had grown by 61.3-times, from 864 thousand megawatt hours to 52,958 thousand megawatt hours.^[https://www.eia.gov/electricity/monthly/epm_table_grapher.php?t=epmt_1_01]. At the same time, solar also became more economical: photovoltaic module costs fell from \$3.37/peak watt to \$0.48/peak watt -- a 86% reduction in cost.

The increased affordability of solar among other advanced technologies opens the possibility for constructing buildings that are hyper energy efficient. For example, the Net Zero Energy Residential Test Facility is a house that produces as much energy as it uses over the course of a year. Engineered and constructed by the [National Institute of Standards and Technology (NIST)](https://pages.nist.gov/netzero), the lab home was designed to be approximately 60 percent more energy efficient than typical homes. In order to achieve net zero energy, the lab home needs to produce an energy surplus and overcome the energy consumption of a simulated family of four. In fact, within its first year, the facility produced an energy surplus that is enough to power an electric car for 1400 miles.

The test bed also generates an extraordinary amount of data that help engineers study how to make more energy efficient homes and may one day inform building standards and policies. As a first step with R, we tap into one slice of the net zero house's photovoltaic time series data, which is made available publicly at  [https://s3.amazonaws.com/nist-netzero/2015-data-files/PV-hour.csv](https://s3.amazonaws.com/nist-netzero/2015-data-files/PV-hour.csv). This data set contains hourly estimates of solar energy production and exposure on the Net Zero home's solar panels.

Suppose we wanted to know how much energy the solar arrays are exposed to in an average hour and how variable that exposure is. With only a few lines of code, we can import and summarize the information.  To start, we load the `pacman` package and use `p_load` to load the `readr` package.

```{r}
#Load libraries
  library(pacman)
  p_load(readr)
```

With the basic functions loaded, `read_csv` is used to import a comma separated values (CSV) file stored at the given `url`, which is then loaded into memory as a data frame labeled `solar`. We can check the dimensions of the data frame using `dim`: it has n = 8,737 with 32 columns.

```{r}
#Create string object with URL
  url <- "https://s3.amazonaws.com/nist-netzero/2015-data-files/PV-hour.csv"

#Read data direct from web
  solar <- read_csv(url)
  
#Check dimensions
  dim(solar)
```

As we are primarily interested in the total amount of sunlight hitting the solar arrays at any given hour (kWh), we focus in on the variable `PV_PVInsolationHArray` in data frame `solar`. To take a sneak peek of the data, we can use `head` to retrieve the first six observations.

```{r}
  head(solar$PV_PVInsolationHArray)
```

To answer our questions, we can obtain a concise `summary` to gauge the hourly variability. As it turns out, the summary indicates that the photovoltaic arrays are exposed to fairly small amounts of energy for the majority of hours as indicated by the small median relative to the mean, but there are occasional periods with intense energy exposure.

```{r}
  summary(solar$PV_PVInsolationHArray)
```

This can be more concisely summarized as the coefficient of variation ($CV = \frac{\text{standard deviation}}{\text{mean}}$) -- the ratio of the standard deviation and the mean. Values of the CV that exceed $CV = 1$ indicate greater dispersion. Otherwise stated, the data may be *wider than it is tall*, therefore greater vales of CV indicate there may be more noise and less consistency in the data. We compute the `mean` and standard deviation `sd`. The resulting CV indicates that one standard deviation is 1.5-times as wide as the mean, suggesting some visible degree of variability in hourly sun exposure.

```{r}
  a <- mean(solar$PV_PVInsolationHArray)
  b <- sd(solar$PV_PVInsolationHArray)
  print(b/a)
```

With only a few lines of code, we have shown how programming can make data analysis an efficient process. In the context of policy, programming removes the tedium of spreadsheeting, allowing an analysis to be delivered using only a few decisive keystrokes.
